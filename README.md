# GNX CLI - AI Agent with Desktop & Mobile Control

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![Status](https://img.shields.io/badge/status-active-success.svg)

**GNX CLI** is a next-generation AI agent capable of perceiving and manipulating real-world interfaces. Built on a modular architecture, it combines **Native Tool Calling** (Llama 4 Scout/Groq) for rapid logic with a specialized **Vision Agent** (Qwen3-VL/Novita) for high-fidelity UI automation on both desktop and mobile. Developed by **Gokulbarath**.

![GNX CLI Demo](./imgs/img1.png)

## ğŸš€ Key Features

- **ğŸ§  Hybrid Intelligence:** Fast orchestrator LLM (Llama 4, Gemini, or GLM) plus specialized VLM (Qwen3-VL) for sight.
- **ğŸ‘ï¸ Autonomous Vision Agent:** Sub-agent loop that can see screens, reason about UI, and act (click, swipe, type).
- **ğŸ”Œ MCP Support:** Works with the Model Context Protocol (GitHub, Filesystem, Memory servers).
- **ğŸ“± Mobile Automation:** Deep ADB integration for taps, swipes, and text input.
- **ğŸ’» Desktop Automation:** Mouse/keyboard control via PyAutoGUI with visual feedback loops.
- **ğŸ“ Modular Tooling:** Atomic tools for file ops, web search, system control, and UI automation.

## ğŸ“± Mobile Demo

<video controls width="700">
	 <source src="./imgs/GNX_CLI_MOBILE_DEMO.mov" type="video/quicktime">
	 Your browser does not support embedded video. [Download the demo](./imgs/GNX_CLI_MOBILE_DEMO.mov).
</video>

This clip shows GNX CLI running a full mobile automation sequence from the latest build.

## ğŸ—ï¸ Architecture

![GNX Architecture](./imgs/architecture.png)
![GNX Sequence Flow](./imgs/sequence_flow.png)

### Workflow: User Goal â†’ Llama 4 Scout â†’ Action Execution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. USER GOAL                                                â”‚
â”‚    "Open calculator on desktop"                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
					  â”‚
					  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. LLAMA 4 SCOUT ENGINE (Main LLM)                          â”‚
â”‚    - Understands user intent                                â”‚
â”‚    - Native tool calling (no ReAct parsing needed)          â”‚
â”‚    - Multimodal vision for screenshot analysis              â”‚
â”‚    - Plans action sequence                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
					  â”‚
					  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. SCREENSHOT CAPTURE                                       â”‚
â”‚    - Takes current screen/phone screenshot                  â”‚
â”‚    - Sends image directly to Llama 4 Scout                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
					  â”‚
					  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. NATIVE TOOL CALLING                                      â”‚
â”‚    - Model decides which tools to use                       â”‚
â”‚    - Returns structured tool calls                          â”‚
â”‚    - Handles images natively (multimodal)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
					  â”‚
					  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. ACTION EXECUTION                                         â”‚
â”‚    - Click/tap at coordinates                               â”‚
â”‚    - Type text                                              â”‚
â”‚    - Press hotkeys                                          â”‚
â”‚    - Swipe/drag                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
					  â”‚
					  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. VERIFICATION LOOP                                        â”‚
â”‚    - Take new screenshot                                    â”‚
â”‚    - Check if goal achieved                                 â”‚
â”‚    - Continue or report success                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### High-Level Routing

```mermaid
graph TD;
	 User[User Input] --> Engine[GNX Engine];
	 Engine -->|Selects Tool| Router{Tool Router};
    
	 subgraph "Standard Tools"
	 Router -->|File Ops| Files[FileSystem / Search];
	 Router -->|Web| Web[DuckDuckGo / Jina];
	 Router -->|MCP| MCP[MCP Servers];
	 end
    
	 subgraph "Automation & Vision"
	 Router -->|Simple| Atomic[Atomic Actions];
	 Atomic --> Desktop[Desktop Control];
	 Atomic --> Mobile[Mobile/ADB];
    
	 Router -->|Complex UI Tasks| Handoff[activate_vision_agent];
	 Handoff --> VisionLoop((Vision Agent Loop));
	 end
    
	 Files --> Output[Result];
	 Web --> Output;
	 MCP --> Output;
	 Desktop --> Output;
	 Mobile --> Output;
	 VisionLoop --> Output;
    
	 Output --> Engine;
	 Engine --> User;
```

#### Vision Agent Loop
When `activate_vision_agent` is called, the system switches to a VLM-driven feedback loop:

```mermaid
graph TD;
	 Start([Task Received]) --> Capture[Capture High-Res Screenshot];
	 Capture --> VLM[Qwen3-VL Analysis];
    
	 VLM -->|Reasoning + JSON| Decision{Decision};
    
	 Decision -->|Action| Executor[Execute Action];
	 Executor -->|Wait for UI| Capture;
    
	 Decision -->|Terminate| Success([Task Complete]);
	 Decision -->|Error| Fail([Report Failure]);
```

## ğŸ› ï¸ Installation

### Requirements
- Python 3.10+
- Windows/Mac/Linux
- For mobile: ADB (Android Debug Bridge) and a connected Android device

### Setup

```bash
git clone https://github.com/Gokulbarath/GNX-CLI.git
cd "GNX CLI"

python -m venv .venv
.venv\Scripts\activate  # Mac/Linux: source .venv/bin/activate

pip install -r requirements.txt

# Configure environment
copy .env.example .env  # Mac/Linux: cp .env.example .env
```

## ğŸ’» Usage

Start the CLI:

```bash
python main.py
```

### Example Commands

1. General reasoning & files
	- "List all python files in src/tools and tell me what they do."
2. Web search
	- "Search for the latest features in Python 3.13."
3. Vision Agent (mobile)
	- Ensure your Android device is connected via ADB.
	- "Open Settings, find 'Display', and turn on Dark Mode." (Agent navigates, scrolls, and taps based on visual cues.)
4. Vision Agent (desktop)
	- "Open Calculator, calculate 55 * 12, and tell me the result."

#### Desktop Automation (sample transcript)
```
GNX: "Use computer use and open calculator"
âœ“ computer_screenshot: Screenshot captured
âœ“ computer_control: Click on Start button (679, 1047)
âœ“ computer_control: Type "calculator"
âœ“ computer_control: Click on Calculator app (725, 491)
âœ“ Task completed: Calculator opened successfully
```

#### Mobile Automation (sample transcript)
```
GNX: "Open Settings on my phone"
âœ“ mobile_devices: Connected devices found
âœ“ mobile_connect: Connected to device RZCX904D1QV
âœ“ mobile_screenshot: Screen captured
âœ“ mobile_control: Tap on Settings icon
âœ“ Task completed: Settings app opened
```

#### File Operations
```
GNX: "List all Python files in src folder"
GNX: "Read the contents of main.py"
GNX: "Create a new file called notes.txt with content 'Hello World'"
```

#### Web Search
```
GNX: "Search for latest Python 3.13 features"
GNX: "Fetch the content from github.com"
```

#### Task Management
```
GNX: "Create a TODO list with: Task 1, Task 2, Task 3"
GNX: "Show my TODO list"
GNX: "Mark the first task as complete"
```

## âš™ï¸ Configuration

GNX CLI uses environment variables (set in `.env`).

| Variable | Description | Required |
|----------|-------------|----------|
| GROQ_API_KEY | API key for Groq models (Llama 4 Scout) | Yes |
| GOOGLE_API_KEY | API key for Google Gemini models | No (fallback) |
| HF_TOKEN | HuggingFace token for V_action vision model | Optional |
| ZHIPUAI_API_KEY | API key for ZhipuAI's GLM-4.5 series (text-only, see GLMinfo.md) | Yes |
| GNX_DEFAULT_PROVIDER | Default LLM provider (`glm`, `groq`, or `gemini`) | No (default: `glm`) |

Quick setup:

```bash
cp .env.example .env
# edit .env with your keys
```

## ğŸ”§ Tools Reference

### Desktop Control
```python
computer_screenshot()
computer_control(instruction="Click on the Start button")
computer_type_text(text="hello world", press_enter=True)
computer_hotkey(keys="ctrl,c")
computer_wait(seconds=2.0)
```

### Mobile Control
```python
mobile_devices()
mobile_connect(device_id="DEVICE_ID")
mobile_screenshot()
mobile_control(instruction="Tap on Settings icon")
mobile_tap(x=100, y=200)
mobile_swipe(direction="up")
mobile_button(button="back")
```

### File Operations
```python
ls(path="src")
read_file(path="main.py")
write_file(path="test.txt", content="Hello")
edit_file(path="test.txt", old="Hello", new="Hi")
glob(pattern="**/*.py")
grep(query="import", path="src")
```

## ğŸ§­ Native Tool Calling

GNX uses **native tool calling** with Llama 4 Scout:

1. Understanding â€” Llama 4 Scout parses intent and visuals.
2. Tool selection â€” Model decides which tool(s) to invoke.
3. Execution â€” Tools run and return structured results.
4. Observation â€” Model inspects results/screenshots and continues or finishes.

## ğŸ“‚ Project Structure

```
GNX CLI/
â”œâ”€â”€ main.py                     # Entry point
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ imgs/                       # Assets (demo, architecture, LAMx)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ vision/             # Vision agent loop & prompts
â”‚   â”œâ”€â”€ gnx_engine/             # Orchestrator, adapters, prompts
â”‚   â”œâ”€â”€ mcp/                    # Model Context Protocol client
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ desktop/            # Mouse/keyboard/screenshot
â”‚   â”‚   â”œâ”€â”€ mobile/             # ADB/touch/system
â”‚   â”‚   â”œâ”€â”€ handoff/            # Sub-agent triggers
â”‚   â”‚   â”œâ”€â”€ file_ops.py         # File operations
â”‚   â”‚   â”œâ”€â”€ filesystem.py       # Directory listing
â”‚   â”‚   â”œâ”€â”€ system.py           # System utilities
â”‚   â”‚   â”œâ”€â”€ search.py           # File search
â”‚   â”‚   â”œâ”€â”€ todos.py            # TODO management
â”‚   â”‚   â”œâ”€â”€ web_search.py       # Web search
â”‚   â”‚   â””â”€â”€ ui_automation.py    # UI automation helpers
â”‚   â”œâ”€â”€ ui/                     # Display utilities
â”‚   â”œâ”€â”€ utils/                  # Logging, token counting
â”‚   â””â”€â”€ vision_client/          # VLM API client and types
â””â”€â”€ .env.example                # Environment template
```

## ğŸ§¾ Environment Template

```text
# GNX CLI Environment Variables

# Groq API Key (primary orchestrator)
GROQ_API_KEY=your_groq_api_key_here

# Google Gemini API Key (fallback/alternative)
GOOGLE_API_KEY=your_google_api_key_here

# HuggingFace Token (for V_action vision model)
HF_TOKEN=your_huggingface_token_here

# ZhipuAI API Key (GLM-4.5 text-only series)
ZHIPUAI_API_KEY=your_zhipuai_api_key_here

# Default provider: glm | groq | gemini
GNX_DEFAULT_PROVIDER=glm

# Optional model overrides
# GROQ_MODEL=meta-llama/llama-4-scout-17b-16e-instruct
# GEMINI_MODEL=gemini-1.5-flash
# GLM_MODEL=glm-4.5
```

## ğŸ”‘ Key Technologies

- **Llama 4 Scout** â€” Multimodal LLM with native tool calling (128K context)
- **LangChain** â€” Agent framework and tool management
- **Groq** â€” Fast inference API for Llama 4 Scout
- **Rich** â€” Terminal UI
- **PyAutoGUI + MSS** â€” Desktop automation and screenshots
- **ADB** â€” Mobile device control (via subprocess)

## ğŸ©º Troubleshooting

- "Could not import ddgs python package":
  ```bash
  pip install -U ddgs duckduckgo-search
  ```
- Mobile screenshot path errors: ensure the workspace path has no special characters, or quote it (`"C:\Users\...\GNX CLI"`).
- Computer screenshot not working: verify display scaling and disable `pyautogui.FAILSAFE` if needed.
- ADB not found: install Android SDK, add ADB to PATH, or set `ADB_EXE = "C:\\path\\to\\adb.exe"` in config.

## ğŸ—ºï¸ Future Roadmap


- [ ] Video recording of actions
- [ ] Multi-device coordination
- [ ] Custom action recording and playback
- [ ] Web UI dashboard
- [ ] Performance optimization and caching
- [ ] Personalization

## ğŸ”— Part of LAMx Project

GNX CLI is a rewritten and evolved version of **[Axolot OS](https://github.com/gokul6350/Axolot-os)**, now optimized as a core component of the **LAMx** projectâ€”an integrated ecosystem for general AI-powered intelligence.

![LAMx Logo](./imgs/LAMx.png)

## ğŸ¤ Contributing

Contributions are welcome! Please open an issue or submit a PR.

## ğŸ“œ License

MIT License â€” see the LICENSE file for details.

---

**Built with â¤ï¸ after a lot of ğŸ’”**
